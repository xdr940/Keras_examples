{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP网络二分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\workpgs\\anaconda\\envs\\PY3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n",
      "F:\\workpgs\\anaconda\\envs\\PY3\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "import keras\n",
    "import os\n",
    "\n",
    "def scale(train, test):#对数据进行规格化，使得分布在[-1,1]内,shape 不变\n",
    "\t# fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "DataFrame = read_csv('dataset.data', header=None, index_col= False)#pandas.DataFrame\n",
    "raw_values = DataFrame.values#pandas.ndarray\n",
    "\n",
    "x = raw_values[:, 0:3]#所有列，0~2号特征为X输入\n",
    "y = keras.utils.to_categorical((raw_values[:, 3]), num_classes=2)#所有列，0号为标签，一共有2个类，本来是数字标类号的变成正交向量标类了\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)#其中20%的数据用于验证集，42是随机种子\n",
    "scaler, train_x_scaled, test_x_scaled = scale(x_train, x_test)#对数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 层次模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 62\n",
      "Trainable params: 62\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelfile = 'modelweight.model' #神经网络权重保存\n",
    "model = Sequential()  \n",
    "model.add(Dense(units=10, activation='sigmoid', input_dim=3))#第一层10个神经元，用sigmoid激活函数，输入维度3\n",
    "model.add(Dropout(0.2))#droupout 层\n",
    "model.add(Dense(units=2, input_dim=10,activation='softmax'))#分类，用softmax做，输出为2d矢量\n",
    "model.summary()#打印出模型概述信息\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)#随机梯度下降做优化\n",
    "model.compile(loss='binary_crossentropy', #二分类用binary交叉熵\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if os.path.exists(modelfile):#如果存在之前训练的权重矩阵，载入模型\n",
    "     model.load_weights(modelfile)\n",
    "else:#否则训练\n",
    "    hist=model.fit(train_x_scaled, y_train,#开始训练\n",
    "              epochs=200,\n",
    "              batch_size=4,validation_data=(test_x_scaled, y_test))\n",
    "    model.save_weights(modelfile) #保存模型权重\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 3ms/step\n",
      "['loss', 'acc']\n",
      "[0.29477190630415739, 0.89830508575601098]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x_scaled, y_test, batch_size=4)#这里做评估，返回误差值和评估标准\n",
    "print(model.metrics_names)\n",
    "print(score)#打印误差值和评估标准值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自测 acc =  0.1864406779661017\n"
     ]
    }
   ],
   "source": [
    "\"\"\"y_test是样本测试集，y_test_是测试集经过模型后的输出，数据结构都为n*2的ndarray\n",
    "    两者相乘，如果一个样本点的label为[1 ,0]，经过模型的输出为[0.9 ,0]相乘就得到[0.9 , 0],该随机矢量无穷范数为0.9，大于阈值0.5，预测正确\n",
    "    如果一个样本点的label为[1 ,0]，经过模型的输出为[0 ,0.9]相乘就得到[0 , 0],该随机矢量无穷范数为0，小于阈值，预测错误\n",
    "\"\"\"\n",
    "y_test_=model.predict(x_test)\n",
    "y_test_acc=abs(y_test_* y_test)\n",
    "\n",
    "acc=0\n",
    "for i in range(y_test_acc.shape[0]):#行数\n",
    "   \n",
    "    if y_test_acc[i][0]>0.5 or y_test_acc[i][1]>0.5:#无穷范数\n",
    "        acc+=1\n",
    "print(\"自测 acc = \",acc/y_test_acc.shape[0])\n",
    "#这里使用模型，顺便测试误差值，结果和上面评估完全一样\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
